{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "#   Import Libraries needed\n",
    "#######################################################################################\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "import time\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.83 s\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "#   Load Training Dataset\n",
    "#######################################################################################\n",
    "tinit = time.time()\n",
    "\n",
    "# read train data set\n",
    "# url = 'https://drive.google.com/file/d/1dTIWNpjlrnTQBIQtaGOh0jCRYZiAQO79/view?usp=sharing'\n",
    "# path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "# output = \"twitterData.csv\"\n",
    "# gdown.download(path, output, quiet=False)\n",
    "%time twitter_data = pd.read_csv(\"../twitterData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>680949</td>\n",
       "      <td>0</td>\n",
       "      <td>2249621587</td>\n",
       "      <td>Fri Jun 19 22:41:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sukumarpant</td>\n",
       "      <td>#brokenpromises...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>406741</td>\n",
       "      <td>0</td>\n",
       "      <td>2059003515</td>\n",
       "      <td>Sat Jun 06 16:03:21 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>MTMSparrow</td>\n",
       "      <td>David Carradine  so sad. Thai's law not sure i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337108</td>\n",
       "      <td>4</td>\n",
       "      <td>2017466467</td>\n",
       "      <td>Wed Jun 03 08:26:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>itsmemcee</td>\n",
       "      <td>A @ 415 B @ 425. Tell your bro i say congrats!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1560887</td>\n",
       "      <td>4</td>\n",
       "      <td>2186457254</td>\n",
       "      <td>Mon Jun 15 18:52:04 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jdfreivald</td>\n",
       "      <td>@littlefluffycat  Indeed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1466295</td>\n",
       "      <td>4</td>\n",
       "      <td>2064458395</td>\n",
       "      <td>Sun Jun 07 06:19:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>CrazyHan</td>\n",
       "      <td>Completed Race 4 Life in 58mins with girlies f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  target          id                          date      flag  \\\n",
       "0      680949       0  2249621587  Fri Jun 19 22:41:08 PDT 2009  NO_QUERY   \n",
       "1      406741       0  2059003515  Sat Jun 06 16:03:21 PDT 2009  NO_QUERY   \n",
       "2     1337108       4  2017466467  Wed Jun 03 08:26:14 PDT 2009  NO_QUERY   \n",
       "3     1560887       4  2186457254  Mon Jun 15 18:52:04 PDT 2009  NO_QUERY   \n",
       "4     1466295       4  2064458395  Sun Jun 07 06:19:20 PDT 2009  NO_QUERY   \n",
       "\n",
       "          user                                               text  \n",
       "0  sukumarpant                                #brokenpromises...   \n",
       "1   MTMSparrow  David Carradine  so sad. Thai's law not sure i...  \n",
       "2    itsmemcee    A @ 415 B @ 425. Tell your bro i say congrats!   \n",
       "3   jdfreivald                          @littlefluffycat  Indeed.  \n",
       "4     CrazyHan  Completed Race 4 Life in 58mins with girlies f...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check form of data\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set part of dataset to be transformed\n",
    "twitter_data_subset = twitter_data  #[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "#   Text preprocessing and transformation of string labels to numeric\n",
    "#######################################################################################\n",
    "\n",
    "# Transform \"0 and 4\" categories to boolean for binary classification\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(twitter_data_subset[\"target\"])\n",
    "y = np.reshape(y,(y.shape[0],1))\n",
    "# # Show the \"transformed\" categories\n",
    "# y = le.transform(twitter_data_subset[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.2 s\n",
      "in argentina any can happen lol we miss u\n"
     ]
    }
   ],
   "source": [
    "### Preprocess tweets text before converting to numerical ###\n",
    "import re\n",
    "\n",
    "def preprocessText(x):\n",
    "    # Convert to lower case\n",
    "    x = str(x).lower()\n",
    "    # # Remove url links\n",
    "    x = re.sub(r'http\\S+', '', x)\n",
    "    # Remove @ tags refer to names of users\n",
    "    x = re.sub(r'\\S*@\\S+', '', x)    \n",
    "    # Remove underscores\n",
    "    x = re.sub(r'_', ' ', x)\n",
    "    # remove special chars\n",
    "    x = re.sub(r'[^\\w ]+', \"\", x)\n",
    "    x = ' '.join(x.split())\n",
    "    if x == '': x = 'unk'\n",
    "    return x\n",
    "\n",
    "# Preprocess tweets text\n",
    "%time twitter_data_subset['text'] = twitter_data_subset['text'].apply(lambda x: preprocessText(x))\n",
    "print(twitter_data_subset['text'].iloc[1000])\n",
    "\n",
    "# txt = \" ss@notoriuS : we LOVE you all______  -&^%+** of lollll ---in Argentina odygsim@gmail.com!!!\"\n",
    "# protxt = preprocessText(txt)\n",
    "# print(protxt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick sentiments to transform to vectors\n",
    "X = twitter_data_subset['text'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the part of the dataset to use if it is very large\n",
    "Xsel = X[:10000] #reshape(len(Xsel),1)\n",
    "ysel = np.squeeze(y[:10000]) #[1:10000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def build_vector_model(mode='count'):\n",
    "    if mode == 'count':\n",
    "        transformer = CountVectorizer()\n",
    "        method = 'count'\n",
    "    if mode == 'tfidf':\n",
    "        transformer =  TfidfVectorizer()\n",
    "        method = 'tfidf'\n",
    "    if mode == 'word_embeddings':\n",
    "        transformer = TextToEmbeddingsTransformer(wordEmbeddingsDict=glove_embedding)\n",
    "        method = 'wordembed'\n",
    "    \n",
    "    print('Using text transformation : ', method)\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using text transformation :  count\n"
     ]
    }
   ],
   "source": [
    "# Pick transformer\n",
    "# model_pipeline = build_vector_model(mode='word_embeddings')\n",
    "model_pipeline = build_vector_model(mode='count')\n",
    "# Tranform to vectors\n",
    "Xsel_transf = model_pipeline.fit_transform(Xsel,ysel)\n",
    "# Xval_transf = model_pipeline.fit_transform(Xval,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to train/validation/test set in order\n",
    "# not to overfit classifiers hyperparameters\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the train dataset in two equal parts : train_gs , test_gs\n",
    "# to use in gridsearch for training/testing\n",
    "Xtrain, Xtotaltest, ytrain, ytotaltest = train_test_split(\n",
    "    Xsel_transf, ysel, test_size=0.3, random_state=42, shuffle=True, stratify=ysel)\n",
    "Xval, Xtest, yval, ytest = train_test_split(\n",
    "    Xtotaltest, ytotaltest, test_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33979  ,  0.20941  ,  0.46348  , -0.64792  , -0.38377  ,\n",
       "        0.038034 ,  0.17127  ,  0.15978  ,  0.46619  , -0.019169 ,\n",
       "        0.41479  , -0.34349  ,  0.26872  ,  0.04464  ,  0.42131  ,\n",
       "       -0.41032  ,  0.15459  ,  0.022239 , -0.64653  ,  0.25256  ,\n",
       "        0.043136 , -0.19445  ,  0.46516  ,  0.45651  ,  0.68588  ,\n",
       "        0.091295 ,  0.21875  , -0.70351  ,  0.16785  , -0.35079  ,\n",
       "       -0.12634  ,  0.66384  , -0.2582   ,  0.036542 , -0.13605  ,\n",
       "        0.40253  ,  0.14289  ,  0.38132  , -0.12283  , -0.45886  ,\n",
       "       -0.25282  , -0.30432  , -0.11215  , -0.26182  , -0.22482  ,\n",
       "       -0.44554  ,  0.2991   , -0.85612  , -0.14503  , -0.49086  ,\n",
       "        0.0082973, -0.17491  ,  0.27524  ,  1.4401   , -0.21239  ,\n",
       "       -2.8435   , -0.27958  , -0.45722  ,  1.6386   ,  0.78808  ,\n",
       "       -0.55262  ,  0.65     ,  0.086426 ,  0.39012  ,  1.0632   ,\n",
       "       -0.35379  ,  0.48328  ,  0.346    ,  0.84174  ,  0.098707 ,\n",
       "       -0.24213  , -0.27053  ,  0.045287 , -0.40147  ,  0.11395  ,\n",
       "        0.0062226,  0.036673 ,  0.018518 , -1.0213   , -0.20806  ,\n",
       "        0.64072  , -0.068763 , -0.58635  ,  0.33476  , -1.1432   ,\n",
       "       -0.1148   , -0.25091  , -0.45907  , -0.096819 , -0.17946  ,\n",
       "       -0.063351 , -0.67412  , -0.068895 ,  0.53604  , -0.87773  ,\n",
       "        0.31802  , -0.39242  , -0.23394  ,  0.47298  , -0.028803 ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ysel = np.squeeze(ysel)\n",
    "# print(ysel)\n",
    "# glove_embedding['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.4 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "# Load glove embeddings into dictionary\n",
    "%time glove = pd.read_csv('..\\data\\glove.6B\\glove.6B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "%time glove_embedding = {key: val.values for key, val in glove.T.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# singledoc = ['bill', 'big']\n",
    "# # testy = np.min([ glove_embedding[token] \n",
    "# #                 if (token in glove_embedding and not token == 'not')\n",
    "# #                 else glove_embedding['unknown'] \n",
    "# #                 for token in singledoc ], axis=0)\n",
    "\n",
    "# testy2 = np.min([ glove_embedding[token] \n",
    "#                      if token in glove_embedding and not token == 'big'\n",
    "#                      else  glove_embedding['unknown']  \n",
    "#                  for token in singledoc                 \n",
    "#                     ], axis=0)\n",
    "# # print(glove_embedding['unknown'])\n",
    "# print(glove_embedding['big'])\n",
    "# print(glove_embedding['bill'])\n",
    "# print(glove_embedding['unknown'])\n",
    "# # print(glove_embedding['nurse'])\n",
    "# print(testy)\n",
    "# if testy.all() == glove_embedding['unknown'].all():\n",
    "#     print('yes')\n",
    "# else:\n",
    "#     print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from tqdm import tqdm # for progressbar\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "class TextToEmbeddingsTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\" A transformer that returns the sentence embedding based on word embeddings\n",
    "    produced by spacy library (GloVe embeddings based)\n",
    "    Parameters\n",
    "    ----------\n",
    "    demo_param : str, default='demo'\n",
    "        A parameter used for demonstation of how to pass and store paramters.\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_features_ : int\n",
    "        The number of features of the data passed to :meth:`fit`.\n",
    "    \"\"\"\n",
    "    def __init__(self, embeddingCalculator='average', \n",
    "                 wordEmbeddingsDict={},\n",
    "                 temporaryEmbeddingsFile='',\n",
    "                 vocabulary=\"en_core_web_sm\"):\n",
    "        \n",
    "        self.embeddingCalculator = embeddingCalculator\n",
    "        self.temporaryEmbeddingsFile = temporaryEmbeddingsFile # 'vecsfile.npy'\n",
    "        self.vocabulary = vocabulary\n",
    "        self.nlp = spacy.load(vocabulary)\n",
    "        self.embeddingsDict = wordEmbeddingsDict\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" Setting the data (X) to being transformed\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The transformer input samples.\n",
    "        y : None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        # X = check_array(X, accept_sparse=True)\n",
    "\n",
    "        self.n_features_ = X.shape[0]\n",
    "\n",
    "        # Return the transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" Takes the input data text (each row is a sentence consisted of words)\n",
    "        and uses spacy's nlp to turn each word to an embedding. Then it uses the\n",
    "        'average','max' or 'min' according to user's preference to outcome the sentence\n",
    "        embedding based on the word embeddings\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse-matrix}, shape (n_samples, n_features)\n",
    "            The transforme input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        X_transformed : array, shape (n_samples, n_features)\n",
    "            The array containing the sentence embedding of each sentence\n",
    "            in ``X``.\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, 'n_features_')\n",
    "\n",
    "        # # Input validation\n",
    "#       # X = check_array(X, accept_sparse=True)\n",
    "\n",
    "        # Check that the input is of the same shape as the one passed\n",
    "        # during fit.\n",
    "        if X.shape[0] != self.n_features_:\n",
    "            raise ValueError('Shape of input is different from what was seen'\n",
    "                             'in `fit`')\n",
    "        \n",
    "        # Set dictionary to be used\n",
    "        embeddingsDict = self.embeddingsDict\n",
    "\n",
    "        \n",
    "        # Calculate X dataset embeddings or load from file\n",
    "        if self.temporaryEmbeddingsFile != '' :\n",
    "            \n",
    "            print('Loading embedding vectors from file : ' + self.temporaryEmbeddingsFile)\n",
    "            Xtrans = np.load(self.temporaryEmbeddingsFile, allow_pickle=True)\n",
    "        \n",
    "        # Case having an embeddings dictionary\n",
    "        elif len(self.embeddingsDict)> 0 :\n",
    "            \n",
    "            # Select the sentence embedding calculation method from word embeddings\n",
    "            if self.embeddingCalculator == 'min':\n",
    "                vector_embedding = lambda singledoc: np.min(\n",
    "                    [ embeddingsDict[token] \n",
    "                     if token in embeddingsDict  \n",
    "                     else  embeddingsDict['unk'] \n",
    "                     for token in singledoc                    \n",
    "                    ],\n",
    "                         axis=0)\n",
    "            elif self.embeddingCalculator == 'max':\n",
    "                vector_embedding = lambda singledoc: np.max(\n",
    "                    [ embeddingsDict[token] \n",
    "                     if token in embeddingsDict \n",
    "                     else  embeddingsDict['unk']\n",
    "                     for token in singledoc\n",
    "                    ], axis=0)\n",
    "            else:\n",
    "                vector_embedding = lambda singledoc: np.mean(\n",
    "                    [ embeddingsDict[token] \n",
    "                     if token in embeddingsDict \n",
    "                     else  embeddingsDict['unk']\n",
    "                     for token in singledoc\n",
    "                    ], axis=0)\n",
    "                \n",
    "#             # Set it up as an extension\n",
    "#             if not Doc.has_extension('vector_except_stopwords'):\n",
    "#                 Doc.set_extension(\"vector_except_stopwords\", getter=vector_except_stopwords)\n",
    "            \n",
    "            # Calc sentences embeddings\n",
    "            XtransArray =[]\n",
    "            # Show progress bar\n",
    "            pbar = tqdm( total=len(X) )\n",
    "            pbar.clear()\n",
    "            \n",
    "            # Convert docs to vector embeddings\n",
    "            for doc in X:\n",
    "                XtransArray.append(vector_embedding(doc))\n",
    "                pbar.update(1)\n",
    "            \n",
    "            pbar.close()\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            Xtrans = np.array(XtransArray)\n",
    "\n",
    "        # Case using spacy's embeddings\n",
    "        else:\n",
    "            \n",
    "            # Select the sentence embedding calculation method from word embeddings\n",
    "            if self.embeddingCalculator == 'min':\n",
    "                vector_except_stopwords = lambda singledoc: np.min(\n",
    "                    [token.vector for token in singledoc if not token.is_stop ], axis=0)\n",
    "            elif self.embeddingCalculator == 'max':\n",
    "                vector_except_stopwords = lambda singledoc: np.max(\n",
    "                    [token.vector for token in singledoc if not token.is_stop], axis=0)\n",
    "            else:\n",
    "                vector_except_stopwords = lambda singledoc: np.mean(\n",
    "                    [token.vector for token in singledoc if not token.is_stop], axis=0)\n",
    "                \n",
    "            # Set it up as an extension\n",
    "            if not Doc.has_extension('vector_except_stopwords'):\n",
    "                Doc.set_extension(\"vector_except_stopwords\", getter=vector_except_stopwords)\n",
    "            \n",
    "            # Calc sentences embeddings\n",
    "            XtransArray =[]\n",
    "            for doc in self.nlp.pipe(X):\n",
    "                XtransArray.append(doc._.vector_except_stopwords)\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            Xtrans = np.array(XtransArray)\n",
    "            \n",
    "        return Xtrans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = Xtrain[2]\n",
    "# vector_except_stopwords = lambda singledoc: np.mean(\n",
    "#     [ glove_embedding[token] \n",
    "#      if token in glove_embedding and not token=='big'\n",
    "#      else  glove_embedding['unk']\n",
    "#      for token in singledoc\n",
    "#     ], axis=0)\n",
    "# vector_except_stopwords(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('fullTransformedSentiments.npy', 'wb') as f:\n",
    "#     np.save(f, np.array(Xtransf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain_transf[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtransf[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # zeroarray =[]\n",
    "# # for i in range(len(X)):\n",
    "# #     if len(X[i])== 0:\n",
    "# #         zeroarray.append(i)\n",
    "# # X[zeroarray[2]]\n",
    "# twitter_data.iloc[zeroarray[1078]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_embedding['unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ysel.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# def describe(x):\n",
    "#     print(\"Type: {}\".format(x.type()))\n",
    "#     print(\"Shape/size: {}\".format(x.shape))\n",
    "#     print(\"Values: \\n{}\".format(x))\n",
    "\n",
    "# batch_size = 12\n",
    "# input_dim = 1000    \n",
    "# x_input = torch.rand(batch_size, input_dim)\n",
    "# describe(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tempfile import TemporaryFile\n",
    "# vecsfile = TemporaryFile()\n",
    "# np.save(vecsfile, vecs)\n",
    "\n",
    "# with open('vecsfile.npy', 'wb') as f:\n",
    "#     np.save(f, np.array(vecs))\n",
    "    \n",
    "# # _ = vecsfile.seek(0)\n",
    "# import numpy as np\n",
    "# testy = np.load('vecsfile.npy',allow_pickle=True)\n",
    "#\n",
    "# # pd.DataFrame(np.asarray(vecs)).to_csv('textvecs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# df['sent_vectors'] = df['tokenized'].apply(\n",
    "#   lambda sent: np.mean([token.vector for token in sent if not token.is_stop], axis=0)\n",
    "# )\n",
    "# #     lambda sent: sent.vector)\n",
    "# df['sent_vectors']\n",
    "\n",
    "# # df = train_data.copy()[1:2000]\n",
    "# # df['tokenized']= df['text'].apply(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: \n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_layers):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        \n",
    "        self.fc = nn.ModuleList()\n",
    "        self.activF = nn.ModuleList()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        \n",
    "        # Get hidden layers number\n",
    "        hidden_dims =  hidden_layers['hidden_layers_dims']\n",
    "        hidden_layers_no = hidden_layers['hidden_layers_no']\n",
    "        \n",
    "        # Create a hidden layer for each\n",
    "        for hidden_layer in range( hidden_layers_no ) :      \n",
    "            \n",
    "            if ( hidden_layer == 0) : # Case of input to 1st hidden layer\n",
    "                self.fc.append( nn.Linear(input_dim, hidden_dims[hidden_layer]) )\n",
    "                # Non-linearity\n",
    "                self.activF.append( nn.ReLU() )\n",
    "            elif (hidden_layer == hidden_layers_no-1): # Case intermediate hidden layer\n",
    "                self.fc.append( nn.Linear(hidden_dims[hidden_layer-1], output_dim) )\n",
    "                # Non-linearity\n",
    "                self.activF.append( nn.ReLU() )\n",
    "            else: # Case last hidden layer to output\n",
    "                self.fc.append( nn.Linear(hidden_dims[hidden_layer-1], hidden_dims[hidden_layer]) )\n",
    "                # Non-linearity\n",
    "                self.activF.append( nn.ReLU() ) \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        # Forward pass all hidden layers with activation functions\n",
    "        for layer in range(self.hidden_layers['hidden_layers_no']):\n",
    "            # Linear function\n",
    "            out = self.fc[layer](out)\n",
    "            # Activation function\n",
    "            out = self.activF[layer](out)\n",
    "        \n",
    "        # Return the softmax\n",
    "        out = F.softmax(out, dim=1)\n",
    "        \n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import from_numpy, tensor\n",
    "import numpy as np\n",
    "\n",
    "class sentimentsDataset(Dataset):\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self, X, y):\n",
    "        self.len = X.shape[0]\n",
    "#         print(X[15,638], X[15,792], X[15,793], X[15,878])\n",
    "        self.x_data = torch.from_numpy(X) #.to_sparse() #0:-1]) #.to_sparse() \n",
    "#         print(self.x_data[15,638], self.x_data[15,792], self.x_data[15,793], self.x_data[15,878])\n",
    "        self.y_data = torch.from_numpy(y) #.to_sparse() #) #.to_sparse()\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class sentimentsPredictionsDataset(Dataset):\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self, X, y):\n",
    "        self.len = X.shape[0]\n",
    "        self.x_data = torch.from_numpy(X)\n",
    "        self.y_data = torch.from_numpy(y)\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from tqdm import tqdm # for progressbar\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "class FeedForwardNNClassifier(ClassifierMixin, BaseEstimator):\n",
    "    \"\"\" A classifier which implements a feed forward neural net algorithm\n",
    "    for sentiment analysis.\n",
    "    Parameters\n",
    "    ----------\n",
    "    demo_param : str, default='demo'\n",
    "        A parameter used for demonstation of how to pass and store paramters.\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_ : ndarray, shape (n_samples, n_features)\n",
    "        The input passed during :meth:`fit`.\n",
    "    y_ : ndarray, shape (n_samples,)\n",
    "        The labels passed during :meth:`fit`.\n",
    "    classes_ : ndarray, shape (n_classes,)\n",
    "        The classes seen at :meth:`fit`.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, num_epochs=10, hidden_layers={'hidden_layers_no' : 2, \n",
    "                                                             'hidden_layers_dims': [50, 50]}\n",
    "                ):\n",
    "        \n",
    "        # Set the NN model dimension parameters and initialize FFFNN\n",
    "        self.input_dim = input_dim\n",
    "        print('Initializing ffnn clasfr with input dim ', self.input_dim)\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"A reference implementation of a fitting function for a classifier.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            The target values. An array of int.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        # Store dataset, labels\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        # Get X dataset input features dimension\n",
    "        self.input_dim = self.X_[0].shape[0]\n",
    "        # Initialize FF neural net model\n",
    "        self.ffnn = FeedforwardNeuralNetModel(input_dim=self.input_dim, \n",
    "                                              output_dim=self.output_dim, hidden_layers=self.hidden_layers)\n",
    "        self.ffnn.to(device)\n",
    "        \n",
    "        # Load model to device = GPU\n",
    "#         self.ffnn.to(device)\n",
    "        # Assign loss function and optimizer\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.SGD(self.ffnn.parameters(), lr=0.3)\n",
    "        \n",
    "        # Create dataset and dataloader for use from pytorch\n",
    "        self.dataset = sentimentsDataset(self.X_,self.y_)\n",
    "        self.train_loader = DataLoader(dataset=self.dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True)#,num_workers=2)\n",
    "        \n",
    "        # Start training\n",
    "        for epoch in tqdm( range(self.num_epochs) ):\n",
    "            \n",
    "            # Initialize training loss and start keeping record\n",
    "            train_loss = 0\n",
    "            \n",
    "            # Loop over dataset batches\n",
    "            for index, data in enumerate(self.train_loader, 0) :\n",
    "\n",
    "                # Get data\n",
    "                inputs, labels = data\n",
    "\n",
    "                # Wrap them in Variable\n",
    "                inputs, labels = inputs, labels\n",
    "\n",
    "                # Clearing the accumulated gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass to get output\n",
    "                preds = self.ffnn.forward(inputs.float())\n",
    "\n",
    "                # Calculate Loss: softmax --> cross entropy loss\n",
    "                loss = self.loss_function(preds, labels)\n",
    "                \n",
    "                # Accumulating the loss over time\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                # Getting gradients w.r.t. parameters\n",
    "                loss.backward()\n",
    "\n",
    "                # Updating parameters\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # # Write loss in file\n",
    "                # f.write(str((epoch+1)) + \",\" + str(train_loss / Xtrain.shape[0]))\n",
    "                # f.write('\\n')\n",
    "                \n",
    "        # Print loss of epoch\n",
    "        print(train_loss)\n",
    "        \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" A reference implementation of a prediction for a classifier.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            The label for each sample is the label of the closest sample\n",
    "            seen during fit.\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "\n",
    "        # Input validation\n",
    "#         X = check_array(X)\n",
    "        # Dummy y labels\n",
    "        y = np.random.randint(2,size=X.shape[0]) #.astype(float)\n",
    "\n",
    "        # Create dataset and dataloader for use from pytorch\n",
    "        pred_dataset = sentimentsPredictionsDataset(X, y)\n",
    "        pred_loader = DataLoader(dataset=pred_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=False)#,num_workers=2)\n",
    "        \n",
    "#         ypred=np.array()\n",
    "        # Loop over all samples\n",
    "        for index, data in enumerate(pred_loader, 0):\n",
    "            # Get data\n",
    "            predInputs, predLabels = data\n",
    "\n",
    "            # Wrap them in Variable\n",
    "            predInputs, predLabels = predInputs, predLabels\n",
    "\n",
    "            # Forward pass to get output\n",
    "            preds = self.ffnn(predInputs.float())\n",
    "#             print(preds.detach().numpy())\n",
    "            \n",
    "            # Keep predicted labels\n",
    "#             ypred = np.append(ypred,torch.argmax(preds, dim=1))\n",
    "            if index == 0 :\n",
    "                ypred = preds.detach().numpy()\n",
    "            else:\n",
    "                ypred = np.vstack( ( ypred,preds.detach().numpy() ) )\n",
    "\n",
    "        return ypred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ffnn clasfr with input dim  100\n"
     ]
    }
   ],
   "source": [
    "mynn_clasf = FeedForwardNNClassifier(input_dim=100, output_dim=2, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = np.random.rand(100,5)\n",
    "# y = np.random.randint(5,size=(100,))\n",
    "# np.unique(y)\n",
    "# ytrain\n",
    "Xtrain[15,12021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(1) tensor(0) tensor(1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:17<01:10,  8.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-a05a68d9ae7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmynn_clasf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-145-510204de25fb>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;31m# Loop over dataset batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;31m# Get data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-144-4c78191415b0>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#) #.to_sparse()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mynn_clasf.fit(Xtrain.toarray(),ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def ffnn_roc_curve_plot(y, ypred_probs, pos_label):\n",
    "    # Get positive sentiments probabilities to use in ROC curve\n",
    "    ypositive_probs = np.array([yi[1] for yi in ypred_probs])\n",
    "    # Calc ROC curve\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, ypositive_probs, pos_label=pos_label)\n",
    "    # Display ROC curve\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,                                          estimator_name='example estimator')\n",
    "    display.plot()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiments probabilities\n",
    "ypred_probs = mynn_clasf.predict(Xtrain.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.4745666e-01, 5.2543368e-02],\n",
       "       [9.9990129e-01, 9.8731747e-05],\n",
       "       [7.7730781e-01, 2.2269224e-01],\n",
       "       ...,\n",
       "       [8.7552041e-01, 1.2447960e-01],\n",
       "       [2.7129194e-02, 9.7287083e-01],\n",
       "       [1.8327050e-01, 8.1672955e-01]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ffnn_roc_curve_plot(ytrain, ypred_probs, pos_label=1)\n",
    "# # Get positive sentiments probabilities to use in ROC curve\n",
    "# ypositive_probs = np.array([yi[1] for yi in ypred])\n",
    "# # Calc ROC curve\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(ytrain, ypositive_probs, pos_label=1)\n",
    "# # Display ROC curve\n",
    "# roc_auc = metrics.auc(fpr, tpr)\n",
    "# display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,                                          estimator_name='example estimator')\n",
    "# display.plot()  \n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      3377\n",
      "           1       0.93      0.91      0.92      3623\n",
      "\n",
      "    accuracy                           0.92      7000\n",
      "   macro avg       0.92      0.92      0.92      7000\n",
      "weighted avg       0.92      0.92      0.92      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predicted labels and show classification report\n",
    "ypred_ = np.argmax(ypred_probs,axis=1)\n",
    "print(classification_report(ytrain,ypred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiments probabilities\n",
    "yval_pred_probs = mynn_clasf.predict(Xval.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ffnn_roc_curve_plot(yval, yval_pred_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74       723\n",
      "           1       0.76      0.71      0.74       777\n",
      "\n",
      "    accuracy                           0.74      1500\n",
      "   macro avg       0.74      0.74      0.74      1500\n",
      "weighted avg       0.74      0.74      0.74      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predicted labels and show classification report\n",
    "yval_pred_ = np.argmax(yval_pred_probs,axis=1)\n",
    "print(classification_report(yval,yval_pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(yi==1 for yi in ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain_transf[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count =0\n",
    "# for i in range(100):\n",
    "#     for j in range(100):\n",
    "#         if (Xtrain_transf[i] == Xtrain_transf[j]).all():\n",
    "#             count+=1\n",
    "\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "# output = loss(input, target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
