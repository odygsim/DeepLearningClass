{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "#   Import Libraries needed\n",
    "#######################################################################################\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "import time\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "#   Load Training Dataset\n",
    "#######################################################################################\n",
    "tinit = time.time()\n",
    "\n",
    "# read train data set\n",
    "# url = 'https://drive.google.com/file/d/1dTIWNpjlrnTQBIQtaGOh0jCRYZiAQO79/view?usp=sharing'\n",
    "# path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "# output = \"twitterData.csv\"\n",
    "# gdown.download(path, output, quiet=False)\n",
    "%time twitter_data = pd.read_csv(\"../data/twitterData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>680949</td>\n",
       "      <td>0</td>\n",
       "      <td>2249621587</td>\n",
       "      <td>Fri Jun 19 22:41:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sukumarpant</td>\n",
       "      <td>#brokenpromises...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>406741</td>\n",
       "      <td>0</td>\n",
       "      <td>2059003515</td>\n",
       "      <td>Sat Jun 06 16:03:21 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>MTMSparrow</td>\n",
       "      <td>David Carradine  so sad. Thai's law not sure i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337108</td>\n",
       "      <td>4</td>\n",
       "      <td>2017466467</td>\n",
       "      <td>Wed Jun 03 08:26:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>itsmemcee</td>\n",
       "      <td>A @ 415 B @ 425. Tell your bro i say congrats!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1560887</td>\n",
       "      <td>4</td>\n",
       "      <td>2186457254</td>\n",
       "      <td>Mon Jun 15 18:52:04 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jdfreivald</td>\n",
       "      <td>@littlefluffycat  Indeed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1466295</td>\n",
       "      <td>4</td>\n",
       "      <td>2064458395</td>\n",
       "      <td>Sun Jun 07 06:19:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>CrazyHan</td>\n",
       "      <td>Completed Race 4 Life in 58mins with girlies f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  target          id                          date      flag  \\\n",
       "0      680949       0  2249621587  Fri Jun 19 22:41:08 PDT 2009  NO_QUERY   \n",
       "1      406741       0  2059003515  Sat Jun 06 16:03:21 PDT 2009  NO_QUERY   \n",
       "2     1337108       4  2017466467  Wed Jun 03 08:26:14 PDT 2009  NO_QUERY   \n",
       "3     1560887       4  2186457254  Mon Jun 15 18:52:04 PDT 2009  NO_QUERY   \n",
       "4     1466295       4  2064458395  Sun Jun 07 06:19:20 PDT 2009  NO_QUERY   \n",
       "\n",
       "          user                                               text  \n",
       "0  sukumarpant                                #brokenpromises...   \n",
       "1   MTMSparrow  David Carradine  so sad. Thai's law not sure i...  \n",
       "2    itsmemcee    A @ 415 B @ 425. Tell your bro i say congrats!   \n",
       "3   jdfreivald                          @littlefluffycat  Indeed.  \n",
       "4     CrazyHan  Completed Race 4 Life in 58mins with girlies f...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check form of data\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set part of dataset to be transformed\n",
    "twitter_data_subset = twitter_data  #[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "#   Text preprocessing and transformation of string labels to numeric\n",
    "#######################################################################################\n",
    "\n",
    "# Transform \"0 and 4\" categories to boolean for binary classification\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(twitter_data_subset[\"target\"])\n",
    "y = np.reshape(y,(y.shape[0],1))\n",
    "# # Show the \"transformed\" categories\n",
    "# y = le.transform(twitter_data_subset[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.2 s\n",
      "in argentina any can happen lol we miss u\n"
     ]
    }
   ],
   "source": [
    "### Preprocess tweets text before converting to numerical ###\n",
    "import re\n",
    "\n",
    "def preprocessText(x):\n",
    "    # Convert to lower case\n",
    "    x = str(x).lower()\n",
    "    # # Remove url links\n",
    "    x = re.sub(r'http\\S+', '', x)\n",
    "    # Remove @ tags refer to names of users\n",
    "    x = re.sub(r'\\S*@\\S+', '', x)    \n",
    "    # Remove underscores\n",
    "    x = re.sub(r'_', ' ', x)\n",
    "    # remove special chars\n",
    "    x = re.sub(r'[^\\w ]+', \"\", x)\n",
    "    x = ' '.join(x.split())\n",
    "    if x == '': x = 'unk'\n",
    "    return x\n",
    "\n",
    "# Preprocess tweets text\n",
    "%time twitter_data_subset['text'] = twitter_data_subset['text'].apply(lambda x: preprocessText(x))\n",
    "print(twitter_data_subset['text'].iloc[1000])\n",
    "\n",
    "# txt = \" ss@notoriuS : we LOVE you all______  -&^%+** of lollll ---in Argentina odygsim@gmail.com!!!\"\n",
    "# protxt = preprocessText(txt)\n",
    "# print(protxt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick sentiments to transform to vectors\n",
    "X = twitter_data_subset['text'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the part of the dataset to use if it is very large\n",
    "Xsel = X[:10000] #reshape(len(Xsel),1)\n",
    "ysel = np.squeeze(y[:10000]) #[1:10000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from tqdm import tqdm # for progressbar\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "class TextToEmbeddingsTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\" A transformer that returns the sentence embedding based on word embeddings\n",
    "    produced by spacy library (GloVe embeddings based)\n",
    "    Parameters\n",
    "    ----------\n",
    "    demo_param : str, default='demo'\n",
    "        A parameter used for demonstation of how to pass and store paramters.\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_features_ : int\n",
    "        The number of features of the data passed to :meth:`fit`.\n",
    "    \"\"\"\n",
    "    def __init__(self, embeddingCalculator='average', \n",
    "                 wordEmbeddingsDict={},\n",
    "                 temporaryEmbeddingsFile='',\n",
    "                 vocabulary=\"en_core_web_sm\"):\n",
    "        \n",
    "        self.embeddingCalculator = embeddingCalculator\n",
    "        self.temporaryEmbeddingsFile = temporaryEmbeddingsFile # 'vecsfile.npy'\n",
    "        self.vocabulary = vocabulary\n",
    "        self.nlp = spacy.load(vocabulary)\n",
    "        self.embeddingsDict = wordEmbeddingsDict\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" Setting the data (X) to being transformed\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The transformer input samples.\n",
    "        y : None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        # X = check_array(X, accept_sparse=True)\n",
    "\n",
    "        self.n_features_ = X.shape[0]\n",
    "\n",
    "        # Return the transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" Takes the input data text (each row is a sentence consisted of words)\n",
    "        and uses spacy's nlp to turn each word to an embedding. Then it uses the\n",
    "        'average','max' or 'min' according to user's preference to outcome the sentence\n",
    "        embedding based on the word embeddings\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse-matrix}, shape (n_samples, n_features)\n",
    "            The transforme input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        X_transformed : array, shape (n_samples, n_features)\n",
    "            The array containing the sentence embedding of each sentence\n",
    "            in ``X``.\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, 'n_features_')\n",
    "\n",
    "        # # Input validation\n",
    "#       # X = check_array(X, accept_sparse=True)\n",
    "\n",
    "        # Check that the input is of the same shape as the one passed\n",
    "        # during fit.\n",
    "        if X.shape[0] != self.n_features_:\n",
    "            raise ValueError('Shape of input is different from what was seen'\n",
    "                             'in `fit`')\n",
    "        \n",
    "        # Set dictionary to be used\n",
    "        embeddingsDict = self.embeddingsDict\n",
    "\n",
    "        \n",
    "        # Calculate X dataset embeddings or load from file\n",
    "        if self.temporaryEmbeddingsFile != '' :\n",
    "            \n",
    "            print('Loading embedding vectors from file : ' + self.temporaryEmbeddingsFile)\n",
    "            Xtrans = np.load(self.temporaryEmbeddingsFile, allow_pickle=True)\n",
    "        \n",
    "        # Case having an embeddings dictionary\n",
    "        elif len(self.embeddingsDict)> 0 :\n",
    "            \n",
    "            # Select the sentence embedding calculation method from word embeddings\n",
    "            if self.embeddingCalculator == 'min':\n",
    "                vector_embedding = lambda singledoc: np.min(\n",
    "                    [ embeddingsDict[token] \n",
    "                     if token in embeddingsDict  \n",
    "                     else  embeddingsDict['unk'] \n",
    "                     for token in singledoc                    \n",
    "                    ],\n",
    "                         axis=0)\n",
    "            elif self.embeddingCalculator == 'max':\n",
    "                vector_embedding = lambda singledoc: np.max(\n",
    "                    [ embeddingsDict[token] \n",
    "                     if token in embeddingsDict \n",
    "                     else  embeddingsDict['unk']\n",
    "                     for token in singledoc\n",
    "                    ], axis=0)\n",
    "            else:\n",
    "                vector_embedding = lambda singledoc: np.mean(\n",
    "                    [ embeddingsDict[token] \n",
    "                     if token in embeddingsDict \n",
    "                     else  embeddingsDict['unk']\n",
    "                     for token in singledoc\n",
    "                    ], axis=0)\n",
    "                \n",
    "#             # Set it up as an extension\n",
    "#             if not Doc.has_extension('vector_except_stopwords'):\n",
    "#                 Doc.set_extension(\"vector_except_stopwords\", getter=vector_except_stopwords)\n",
    "            \n",
    "            # Calc sentences embeddings\n",
    "            XtransArray =[]\n",
    "            # Show progress bar\n",
    "            pbar = tqdm( total=len(X) )\n",
    "            pbar.clear()\n",
    "            \n",
    "            # Convert docs to vector embeddings\n",
    "            for doc in X:\n",
    "                XtransArray.append(vector_embedding(doc))\n",
    "                pbar.update(1)\n",
    "            \n",
    "            pbar.close()\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            Xtrans = np.array(XtransArray)\n",
    "\n",
    "        # Case using spacy's embeddings\n",
    "        else:\n",
    "            \n",
    "            # Select the sentence embedding calculation method from word embeddings\n",
    "            if self.embeddingCalculator == 'min':\n",
    "                vector_except_stopwords = lambda singledoc: np.min(\n",
    "                    [token.vector for token in singledoc if not token.is_stop ], axis=0)\n",
    "            elif self.embeddingCalculator == 'max':\n",
    "                vector_except_stopwords = lambda singledoc: np.max(\n",
    "                    [token.vector for token in singledoc if not token.is_stop], axis=0)\n",
    "            else:\n",
    "                vector_except_stopwords = lambda singledoc: np.mean(\n",
    "                    [token.vector for token in singledoc if not token.is_stop], axis=0)\n",
    "                \n",
    "            # Set it up as an extension\n",
    "            if not Doc.has_extension('vector_except_stopwords'):\n",
    "                Doc.set_extension(\"vector_except_stopwords\", getter=vector_except_stopwords)\n",
    "            \n",
    "            # Calc sentences embeddings\n",
    "            XtransArray =[]\n",
    "            for doc in self.nlp.pipe(X):\n",
    "                XtransArray.append(doc._.vector_except_stopwords)\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            Xtrans = np.array(XtransArray)\n",
    "            \n",
    "        return Xtrans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def build_vector_model(mode='count'):\n",
    "    if mode == 'count':\n",
    "        transformer = CountVectorizer()\n",
    "        method = 'count'\n",
    "    if mode == 'tfidf':\n",
    "        transformer =  TfidfVectorizer()\n",
    "        method = 'tfidf'\n",
    "    if mode == 'word_embeddings':\n",
    "        transformer = TextToEmbeddingsTransformer(wordEmbeddingsDict=glove_embedding)\n",
    "        method = 'wordembed'\n",
    "    \n",
    "    print('Using text transformation : ', method)\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.29 s\n",
      "Wall time: 4.44 s\n"
     ]
    }
   ],
   "source": [
    "# Load glove embeddings into dictionary\n",
    "%time glove = pd.read_csv('..\\data\\glove.6B\\glove.6B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "%time glove_embedding = {key: val.values for key, val in glove.T.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▏                                                           | 1922/10000 [00:00<00:00, 19080.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using text transformation :  wordembed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 19114.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Pick transformer\n",
    "# model_pipeline = build_vector_model(mode='word_embeddings')\n",
    "model_pipeline = build_vector_model(mode='word_embeddings')\n",
    "# Tranform to vectors\n",
    "Xsel_transf = model_pipeline.fit_transform(Xsel,ysel)\n",
    "# Xval_transf = model_pipeline.fit_transform(Xval,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to train/validation/test set in order\n",
    "# not to overfit classifiers hyperparameters\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the train dataset in two equal parts : train_gs , test_gs\n",
    "# to use in gridsearch for training/testing\n",
    "Xtrain, Xtotaltest, ytrain, ytotaltest = train_test_split(\n",
    "    Xsel_transf, ysel, test_size=0.3, random_state=42, shuffle=True, stratify=ysel)\n",
    "Xval, Xtest, yval, ytest = train_test_split(\n",
    "    Xtotaltest, ytotaltest, test_size=0.5, random_state=42, shuffle=True, stratify=ytotaltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ysel = np.squeeze(ysel)\n",
    "# print(ysel)\n",
    "# glove_embedding['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# singledoc = ['bill', 'big']\n",
    "# # testy = np.min([ glove_embedding[token] \n",
    "# #                 if (token in glove_embedding and not token == 'not')\n",
    "# #                 else glove_embedding['unknown'] \n",
    "# #                 for token in singledoc ], axis=0)\n",
    "\n",
    "# testy2 = np.min([ glove_embedding[token] \n",
    "#                      if token in glove_embedding and not token == 'big'\n",
    "#                      else  glove_embedding['unknown']  \n",
    "#                  for token in singledoc                 \n",
    "#                     ], axis=0)\n",
    "# # print(glove_embedding['unknown'])\n",
    "# print(glove_embedding['big'])\n",
    "# print(glove_embedding['bill'])\n",
    "# print(glove_embedding['unknown'])\n",
    "# # print(glove_embedding['nurse'])\n",
    "# print(testy)\n",
    "# if testy.all() == glove_embedding['unknown'].all():\n",
    "#     print('yes')\n",
    "# else:\n",
    "#     print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = Xtrain[2]\n",
    "# vector_except_stopwords = lambda singledoc: np.mean(\n",
    "#     [ glove_embedding[token] \n",
    "#      if token in glove_embedding and not token=='big'\n",
    "#      else  glove_embedding['unk']\n",
    "#      for token in singledoc\n",
    "#     ], axis=0)\n",
    "# vector_except_stopwords(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('fullTransformedSentiments.npy', 'wb') as f:\n",
    "#     np.save(f, np.array(Xtransf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain_transf[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtransf[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # zeroarray =[]\n",
    "# # for i in range(len(X)):\n",
    "# #     if len(X[i])== 0:\n",
    "# #         zeroarray.append(i)\n",
    "# # X[zeroarray[2]]\n",
    "# twitter_data.iloc[zeroarray[1078]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_embedding['unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ysel.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# def describe(x):\n",
    "#     print(\"Type: {}\".format(x.type()))\n",
    "#     print(\"Shape/size: {}\".format(x.shape))\n",
    "#     print(\"Values: \\n{}\".format(x))\n",
    "\n",
    "# batch_size = 12\n",
    "# input_dim = 1000    \n",
    "# x_input = torch.rand(batch_size, input_dim)\n",
    "# describe(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tempfile import TemporaryFile\n",
    "# vecsfile = TemporaryFile()\n",
    "# np.save(vecsfile, vecs)\n",
    "\n",
    "# with open('vecsfile.npy', 'wb') as f:\n",
    "#     np.save(f, np.array(vecs))\n",
    "    \n",
    "# # _ = vecsfile.seek(0)\n",
    "# import numpy as np\n",
    "# testy = np.load('vecsfile.npy',allow_pickle=True)\n",
    "#\n",
    "# # pd.DataFrame(np.asarray(vecs)).to_csv('textvecs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# df['sent_vectors'] = df['tokenized'].apply(\n",
    "#   lambda sent: np.mean([token.vector for token in sent if not token.is_stop], axis=0)\n",
    "# )\n",
    "# #     lambda sent: sent.vector)\n",
    "# df['sent_vectors']\n",
    "\n",
    "# # df = train_data.copy()[1:2000]\n",
    "# # df['tokenized']= df['text'].apply(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "# # Use cuda if present\n",
    "# device = \"cpu\"\n",
    "# if torch.cuda.is_available():\n",
    "#     device = \"cuda:0\"\n",
    "#     if torch.cuda.device_count() > 1:\n",
    "#         net = nn.DataParallel(net)\n",
    "# net.to(device)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"Device available for running: \")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_layers, activation_function):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        \n",
    "        self.fc = nn.ModuleList()\n",
    "        self.activF = nn.ModuleList()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        \n",
    "        # Get hidden layers number\n",
    "        hidden_dims =  hidden_layers['hidden_layers_dims']\n",
    "        hidden_layers_no = hidden_layers['hidden_layers_no']\n",
    "        \n",
    "        # Create a hidden layer for each\n",
    "        for hidden_layer in range( hidden_layers_no ) :      \n",
    "            \n",
    "            if ( hidden_layer == 0) : # Case of input to 1st hidden layer\n",
    "                self.fc.append( nn.Linear(input_dim, hidden_dims[hidden_layer]) )\n",
    "                # Non-linearity\n",
    "                self.activF.append( nn.ReLU() )\n",
    "            elif (hidden_layer == hidden_layers_no-1): # Case intermediate hidden layer\n",
    "                self.fc.append( nn.Linear(hidden_dims[hidden_layer-1], output_dim) )\n",
    "                # Non-linearity\n",
    "                self.activF.append( nn.ReLU() )\n",
    "            else: # Case last hidden layer to output\n",
    "                self.fc.append( nn.Linear(hidden_dims[hidden_layer-1], hidden_dims[hidden_layer]) )\n",
    "                # Non-linearity\n",
    "                self.activF.append( nn.ReLU() ) \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        # Forward pass all hidden layers with activation functions\n",
    "        for layer in range(self.hidden_layers['hidden_layers_no']):\n",
    "            # Linear function\n",
    "            out = self.fc[layer](out)\n",
    "            # Activation function\n",
    "            out = self.activF[layer](out)\n",
    "        \n",
    "        # Return the softmax\n",
    "        out = F.softmax(out, dim=1)\n",
    "        \n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import from_numpy, tensor\n",
    "import numpy as np\n",
    "\n",
    "class sentimentsDataset(Dataset):\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self, X, y):\n",
    "        self.len = X.shape[0]\n",
    "#         print(X[15,638], X[15,792], X[15,793], X[15,878])\n",
    "        self.x_data = torch.from_numpy(X) #.to_sparse() #0:-1]) #.to_sparse() \n",
    "#         print(self.x_data[15,638], self.x_data[15,792], self.x_data[15,793], self.x_data[15,878])\n",
    "        self.y_data = torch.from_numpy(y) #.to_sparse() #) #.to_sparse()\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class sentimentsPredictionsDataset(Dataset):\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self, X, y):\n",
    "        self.len = X.shape[0]\n",
    "        self.x_data = torch.from_numpy(X)\n",
    "        self.y_data = torch.from_numpy(y)\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (<ipython-input-181-943c469486f7>, line 242)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-181-943c469486f7>\"\u001b[1;36m, line \u001b[1;32m242\u001b[0m\n\u001b[1;33m    self.optimizer_() = optim.Adam()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm # for progressbar\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "class FeedForwardNNClassifier(ClassifierMixin, BaseEstimator):\n",
    "    \"\"\" A classifier which implements a feed forward neural net algorithm\n",
    "    for sentiment analysis.\n",
    "    Parameters\n",
    "    ----------\n",
    "    demo_param : str, default='demo'\n",
    "        A parameter used for demonstation of how to pass and store paramters.\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_ : ndarray, shape (n_samples, n_features)\n",
    "        The input passed during :meth:`fit`.\n",
    "    y_ : ndarray, shape (n_samples,)\n",
    "        The labels passed during :meth:`fit`.\n",
    "    classes_ : ndarray, shape (n_classes,)\n",
    "        The classes seen at :meth:`fit`.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim=2, num_epochs=10, \n",
    "                 hidden_layers={'hidden_layers_no' : 2, 'hidden_layers_dims': [50, 50]},\n",
    "                 activation_function = 'ReLU', loss_function='CrossEntropy', \n",
    "                 optimizer='SGD', learning_rate=0.005, batch_size=32,\n",
    "                 plot_loss=False\n",
    "                ):\n",
    "        \n",
    "        # Set the NN model dimension parameters and initialize FFFNN\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.num_epochs = num_epochs\n",
    "        self.train_loss = []\n",
    "        self.plot_loss = plot_loss\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.activation_function = activation_function\n",
    "        self.loss_function = loss_function\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"A reference implementation of a fitting function for a classifier.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            The target values. An array of int.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        \n",
    "        # # Sparse matrix check\n",
    "        # scipy.sparse.issparse(my_matrix)\n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        # Store dataset, labels\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        # Get X dataset input features dimension\n",
    "        self.input_dim = self.X_[0].shape[0]\n",
    "        \n",
    "        # Set NN activation function and loss function\n",
    "        self.set_nn_specifics()\n",
    "        \n",
    "        # Initialize FF neural net model\n",
    "        self.ffnn = FeedforwardNeuralNetModel(input_dim=self.input_dim, \n",
    "                                              output_dim=self.output_dim, \n",
    "                                              hidden_layers=self.hidden_layers)\n",
    "        \n",
    "        # Set an optimizer\n",
    "        self.set_nn_optim()\n",
    "        \n",
    "        # Use cuda if present\n",
    "        self.device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda:0\"\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                self.ffnn = nn.DataParallel(self.ffnn)\n",
    "        self.ffnn.to(self.device)\n",
    "        print(self.device)\n",
    "        \n",
    "        \n",
    "        # Create dataset and dataloader for use from pytorch\n",
    "        self.dataset = sentimentsDataset(self.X_,self.y_)\n",
    "        self.train_loader = DataLoader(dataset=self.dataset, \n",
    "                          batch_size=self.batch_size,\n",
    "                          shuffle=True)\n",
    "        \n",
    "        # Initialize train loss array\n",
    "        self.train_loss=[]\n",
    "        \n",
    "        # Start training\n",
    "        for epoch in tqdm( range(self.num_epochs) ):\n",
    "            \n",
    "            # Initialize training loss and start keeping record\n",
    "            train_loss = 0\n",
    "            \n",
    "            # Loop over dataset batches\n",
    "            for index, data in enumerate(self.train_loader, 0) :\n",
    "\n",
    "                # Get data\n",
    "                inputs, labels = data\n",
    "\n",
    "                # Wrap them in Variable\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                # Clearing the accumulated gradients\n",
    "                self.optimizer_.zero_grad()\n",
    "\n",
    "                # Forward pass to get output\n",
    "                preds = self.ffnn.forward(inputs.float())\n",
    "\n",
    "                # Calculate Loss: softmax --> cross entropy loss\n",
    "                loss = self.loss_function_(preds, labels)\n",
    "                \n",
    "                # Accumulating the loss over time\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                # Getting gradients w.r.t. parameters\n",
    "                loss.backward()\n",
    "\n",
    "                # Updating parameters\n",
    "                self.optimizer_.step()\n",
    "                \n",
    "                # # Write loss in file\n",
    "                # f.write(str((epoch+1)) + \",\" + str(train_loss / Xtrain.shape[0]))\n",
    "                # f.write('\\n')\n",
    "        \n",
    "            # Keep train loss per epoch for plotting purposes\n",
    "            self.train_loss.append(train_loss/self.X_.shape[0])\n",
    "            \n",
    "        # Print loss of epoch\n",
    "        print(train_loss)\n",
    "        # Plot train loss if set\n",
    "        if self.plot_loss: self.train_loss_plot()\n",
    "        \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" A reference implementation of a prediction for a classifier.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            The label for each sample is the label of the closest sample\n",
    "            seen during fit.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get classes prediction probabilities\n",
    "        ypred_probs = self.predict_proba(X)\n",
    "        # Return the prevailing class (argmax)\n",
    "        ypred = np.argmax(ypred_probs, axis=1)\n",
    "\n",
    "        return ypred\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\" A reference implementation of a prediction for a classifier.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            The label for each sample is the probability of each class\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "\n",
    "        # Input validation\n",
    "#         X = check_array(X)\n",
    "        # Dummy y labels\n",
    "        y = np.random.randint(2,size=X.shape[0]) #.astype(float)\n",
    "\n",
    "        # Create dataset and dataloader for use from pytorch\n",
    "        pred_dataset = sentimentsPredictionsDataset(X, y)\n",
    "        pred_loader = DataLoader(dataset=pred_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          shuffle=False)\n",
    "\n",
    "        # Loop over all samples\n",
    "        for index, data in enumerate(pred_loader, 0):\n",
    "            # Get data\n",
    "            predInputs, predLabels = data\n",
    "\n",
    "            # Wrap them in Variable\n",
    "            predInputs, predLabels = predInputs.to(self.device), predLabels.to(self.device)\n",
    "\n",
    "            # Forward pass to get output\n",
    "            preds = self.ffnn.forward(predInputs.float())\n",
    "        \n",
    "            if index == 0 :\n",
    "                ypred_probs = preds.detach().numpy()\n",
    "            else:\n",
    "                ypred_probs = np.vstack( ( ypred_probs, preds.detach().numpy() ) )\n",
    "\n",
    "        return ypred_probs\n",
    "    \n",
    "    def set_nn_optim(self):\n",
    "        # Select the optimizer\n",
    "        if self.optimizer == 'SGD':\n",
    "            self.optimizer_() = optim.SGD(self.ffnn.parameters(), lr=self.learning_rate)\n",
    "            \n",
    "        elif self.optimizer == 'Momentum': # momentum = friction ( 0 high - 1 low - usual 0.9 )\n",
    "            self.optimizer_() = optim.SGD(self.ffnn.parameters(), lr=self.learning_rate, momentum=0.9)\n",
    "            \n",
    "        elif self.optimizer == 'Nesterov':\n",
    "            self.optimizer_() = optim.SGD(self.ffnn.parameters(), lr=self.learning_rate, momentum=0.9, nesterov=True)\n",
    "            \n",
    "        elif self.optimizer == 'AdaGrad': # scales down gradient vector along steepest dims \n",
    "            # Often stops too early for neural nets - NOT FOR DEEP NN\n",
    "            self.optimizer_() = optim.Adagrad()\n",
    "            \n",
    "        elif self.optimizer == 'RMSProp': # like Adagrad but using gradients of most recent iterations plus\n",
    "            # uses exponential decay. Normal alpha working good : 0.9\n",
    "            self.optimizer_() = optim.RMSprop(self.ffnn.parameters(), lr=self.learning_rate, alpha=0.9)\n",
    "            \n",
    "        elif self.optimizer == 'Adam': # Combination of momentum and Rmsprop\n",
    "            # Usual values for b1=0.9, b2=0.999 and e=10^(-7)\n",
    "            # But it is ADAPTIVE algorithm so we can use learning rate = 0.001 without issue\n",
    "            self.optimizer_ = optim.Adam(self.ffnn.parameters(), lr=self.learning_rate, betas=(0.9, 0.99))\n",
    "            \n",
    "        elif self.optimizer == 'AdaMax': # differentiation of Adam. To use if we have problems with plain Adam\n",
    "            self.optimizer_() = optim.Adamax() \n",
    "            \n",
    "        elif self.optimizer == 'Nadam': # Adam using Nesterov trick - TODO: find how to configure\n",
    "            self.optimizer_() = optim.Adam()\n",
    "    \n",
    "    def set_nn_specifics(self):\n",
    "        # Select loss function\n",
    "        if self.loss_function == 'CrossEntropy':\n",
    "            self.loss_function_ = nn.CrossEntropyLoss()\n",
    "        elif self.loss_function == 'MeanSquaredError':\n",
    "            self.loss_function_ = nn.MSELoss()\n",
    "        elif self.loss_function == 'MeanAbsoluteError':\n",
    "            self.loss_function_ = nn.L1Loss()\n",
    "        elif self.loss_function == 'BinaryCrossEntropy':\n",
    "            self.loss_function_ = nn.BCELoss()\n",
    "        elif self.loss_function == 'HuberLoss':\n",
    "            self.loss_function_ = nn.SmoothL1Loss()\n",
    "        else :\n",
    "            pass\n",
    "        \n",
    "        # Select the activation function\n",
    "        # SELU > ELU > leaky ReLU (and variants) > ReLU > tanh > logistic (sigmoid)\n",
    "        if self.activation_function == 'Sigmoid':\n",
    "            self.activation_function_ = nn.Sigmoid()\n",
    "        elif self.activation_function == 'HyperbolicTangent':\n",
    "            self.activation_function_ = nn.Tanh()\n",
    "        elif self.activation_function == 'ReLU': # all ReLU methods need at least He initialization\n",
    "            self.activation_function_ = nn.ReLU()\n",
    "        elif self.activation_function == 'LeakyReLU': # a can be 0.01 - 0.2 (lectures suggestions), normally 0.3 (keras)\n",
    "            self.activation_function_ = nn.LeakyReLU()\n",
    "        elif self.activation_function == 'SoftPlus':\n",
    "            self.activation_function_ = nn.Softplus()\n",
    "        elif self.activation_function == 'SeLU': \n",
    "            # Scaled ELU : very good for dense sequential nets\n",
    "            # Needs 1) LeCun initialization for hidden layers\n",
    "            # 2) standarized input features (mean 0, stdev 1)\n",
    "            self.activation_function_ = nn.SELU() \n",
    "        elif self.activation_function == 'ELU': # Exponential Linear Unit : usually a=1 / slow to compute\n",
    "            self.activation_function_ = nn.ELU()   \n",
    "        elif self.activation_function == 'RReLU': # Randomized leaky Relu\n",
    "            self.activation_function_ = nn.RReLU()          \n",
    "        elif self.activation_function == 'PReLU': # Parametric leaky Relu\n",
    "            self.activation_function_ = nn.PReLU()\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    def train_loss_plot(self):\n",
    "        epochs = range(1,self.num_epochs+1)\n",
    "        plt.plot(epochs, self.train_loss, 'g', label='Training loss')\n",
    "        plt.title('Training loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn_clasf = FeedForwardNNClassifier(output_dim=2, num_epochs=5, \n",
    "                                     hidden_layers={'hidden_layers_no' : 3, 'hidden_layers_dims': [50, 50, 50]},\n",
    "                                     optimizer='RMSProp', learning_rate=0.001, plot_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.random.rand(100,5)\n",
    "# y = np.random.randint(5,size=(100,))\n",
    "# np.unique(y)\n",
    "# ytrain\n",
    "# Xtrain[15,12021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.7992981672287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "FeedForwardNNClassifier(hidden_layers={'hidden_layers_dims': [50, 50, 50],\n",
       "                                       'hidden_layers_no': 3},\n",
       "                        learning_rate=0.001, num_epochs=5, optimizer='RMSProp',\n",
       "                        plot_loss=True)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffnn_clasf.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def ffnn_roc_curve_plot(y, ypred_probs, pos_label):\n",
    "    # Get positive sentiments probabilities to use in ROC curve\n",
    "    ypositive_probs = np.array([yi[1] for yi in ypred_probs])\n",
    "    # Calc ROC curve\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, ypositive_probs, pos_label=pos_label)\n",
    "    # Display ROC curve\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='example estimator')\n",
    "    display.plot()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiments probabilities\n",
    "ypred_probs = ffnn_clasf.predict_proba(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ypred_=mynn_clasf.predict(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(ypred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ffnn_roc_curve_plot(ytrain, ypred_probs, pos_label=1)\n",
    "# # Get positive sentiments probabilities to use in ROC curve\n",
    "# ypositive_probs = np.array([yi[1] for yi in ypred])\n",
    "# # Calc ROC curve\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(ytrain, ypositive_probs, pos_label=1)\n",
    "# # Display ROC curve\n",
    "# roc_auc = metrics.auc(fpr, tpr)\n",
    "# display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,                                          estimator_name='example estimator')\n",
    "# display.plot()  \n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.82      0.64      3377\n",
      "           1       0.64      0.29      0.40      3623\n",
      "\n",
      "    accuracy                           0.55      7000\n",
      "   macro avg       0.58      0.56      0.52      7000\n",
      "weighted avg       0.58      0.55      0.51      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predicted labels and show classification report\n",
    "ypred_ = np.argmax(ypred_probs,axis=1)\n",
    "print(classification_report(ytrain,ypred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(ypred_probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiments probabilities\n",
    "yval_pred_probs = ffnn_clasf.predict_proba(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ffnn_roc_curve_plot(yval, yval_pred_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.81      0.64       724\n",
      "           1       0.65      0.33      0.43       776\n",
      "\n",
      "    accuracy                           0.56      1500\n",
      "   macro avg       0.59      0.57      0.54      1500\n",
      "weighted avg       0.59      0.56      0.53      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predicted labels and show classification report\n",
    "yval_pred_ = np.argmax(yval_pred_probs,axis=1)\n",
    "print(classification_report(yval,yval_pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(yi==1 for yi in ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain_transf[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count =0\n",
    "# for i in range(100):\n",
    "#     for j in range(100):\n",
    "#         if (Xtrain_transf[i] == Xtrain_transf[j]).all():\n",
    "#             count+=1\n",
    "\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "# output = loss(input, target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare parameters for hyperparameters search\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from scipy.stats import uniform\n",
    "\n",
    "parameters = dict(\n",
    "    num_epochs=range(1,10,1),\n",
    "    batch_size=range(2,100,10),\n",
    "    learning_rate=loguniform(1e-4, 1e-1),\n",
    "    activation_function=['Sigmoid', 'HyperbolicTangent', \n",
    "                         'ReLU', 'LeakyReLU', 'SoftPlus', 'SeLU', 'ELU', 'RReLU', 'PReLU'],\n",
    "#     optimizer=['SGD', 'Momentum', 'Nesterov', 'Adam', 'RMSProp','Adamax', 'AdaGrad', 'Nadam' ],\n",
    "    optimizer=['SGD', 'Momentum', 'Nesterov'],\n",
    "    #loss_function=['BinaryCrossEntropy', 'CrossEntropy', 'MeanSquaredError'], # 'MeanAbsoluteError','HuberLoss'], \n",
    "    hidden_layers=[{'hidden_layers_no' : 2, 'hidden_layers_dims': [50, 50]},\n",
    "                   {'hidden_layers_no' : 2, 'hidden_layers_dims': [100, 100]},\n",
    "                   {'hidden_layers_no' : 2, 'hidden_layers_dims': [300, 300]},\n",
    "                   {'hidden_layers_no' : 3, 'hidden_layers_dims': [50, 50, 50]},\n",
    "                   {'hidden_layers_no' : 3, 'hidden_layers_dims': [100, 100, 100]},\n",
    "                   {'hidden_layers_no' : 3, 'hidden_layers_dims': [300, 300, 300]},\n",
    "                   {'hidden_layers_no' : 3, 'hidden_layers_dims': [500, 200, 200]}\n",
    "                  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:19<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940.812110900879\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:19<00:00,  2.43s/it]\n",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940.812110900879\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:18<00:00,  2.36s/it]\n",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940.812110900879\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:19<00:00,  2.42s/it]\n",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940.812110900879\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:14<00:00,  1.86s/it]\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940.812110900879\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:01<00:00,  5.99it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:00<00:00,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.75913846492767\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:01<00:00,  6.35it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:00<00:00,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.86316871643066\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:01<00:00,  6.67it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:00<00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.85984647274017\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:01<00:00,  6.18it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:00<00:00,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.7543431520462\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:01<00:00,  6.33it/s]\n",
      "  0%|                                                                                            | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.76309090852737\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.33s/it]\n",
      "  0%|                                                                                            | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323.699734210968\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:10<00:00,  1.21s/it]\n",
      "  0%|                                                                                            | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323.699734210968\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:06<00:00,  1.33it/s]\n",
      "  0%|                                                                                            | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321.9253976345062\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████                                                        | 3/9 [00:03<00:07,  1.20s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-218-5a009027036d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                          \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'f1_micro'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'f1_macro'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                          refit='f1_macro')\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msearch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mffnn_clf_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1527\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1528\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1529\u001b[1;33m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[0;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m             random_state=self.random_state))\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-174-bab201f4ded3>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;31m# Updating parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;31m# # Write loss in file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PortableSoftware\\Winpython64-3.8.5.0\\WPy64-3850\\python-3.8.5.amd64\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    110\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "ffnn_clf = FeedForwardNNClassifier(loss_function='CrossEntropy')\n",
    "ffnn_clf_search = RandomizedSearchCV(ffnn_clf, parameters, random_state=0,\n",
    "                         scoring=['accuracy','f1_micro','f1_macro'],\n",
    "                         refit='f1_macro')\n",
    "search=ffnn_clf_search.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33794234509061133"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffnn_clf_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "distributions = dict(C=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2', 'l1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=range(10,5000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate=loguniform(1e-4, 1e-1)\n",
    "# for i in enumerate(learning_rate):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-96c8e3c26a46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m distributions = dict(C=uniform(loc=0,scale=4),\n\u001b[0;32m     10\u001b[0m                      penalty=['l2', 'l1'])\n\u001b[1;32m---> 11\u001b[1;33m clf = RandomizedSearchCV(logistic, parameters, random_state=0,\n\u001b[0m\u001b[0;32m     12\u001b[0m                          \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'f1_micro'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'f1_macro'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                         refit='f1_macro')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'parameters' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=1000,\n",
    "                              random_state=0)\n",
    "# C=uniform(loc=0, scale=4)\n",
    "distributions = dict(C=uniform(loc=0,scale=4),\n",
    "                     penalty=['l2', 'l1'])\n",
    "clf = RandomizedSearchCV(logistic, parameters, random_state=0,\n",
    "                         scoring=['accuracy','f1_micro','f1_macro'],\n",
    "                        refit='f1_macro')\n",
    "search = clf.fit(iris.data, iris.target)\n",
    "search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.stats._distn_infrastructure.rv_frozen at 0x1bb357b0880>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform(loc=0,scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = uniform.rvs(loc=10, scale=2,size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.91867943, 10.58339197, 11.36059496, 11.76778734, 10.329172  ,\n",
       "       10.28218035, 11.88956828, 10.62086698, 10.85483231, 11.43619208])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.10755070e+032 1.16708056e+201 2.26757837e-007 0.00000000e+000\n",
      "             inf 0.00000000e+000             inf 0.00000000e+000\n",
      " 5.30896738e+186             inf]\n"
     ]
    }
   ],
   "source": [
    "s = np.random.(10,1000,10)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "output = loss(m(input), target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5627, 0.3305, 0.2350], requires_grad=True)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0.])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6371, 0.5819, 0.5585], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-208-932cdadf3e64>:3: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = m(input)\n"
     ]
    }
   ],
   "source": [
    "m = nn.LogSoftmax()\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5019, -1.4141, -1.8872],\n",
       "        [-0.6327, -1.2253, -1.7420]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2869, -0.6252, -1.0983],\n",
       "        [ 0.5798, -0.0128, -0.5296]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = nn.NLLLoss()\n",
    "input2=output\n",
    "target=torch.tensor([1,2])\n",
    "output2=k(input2,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5019, -1.4141, -1.8872],\n",
       "        [-0.6327, -1.2253, -1.7420]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
